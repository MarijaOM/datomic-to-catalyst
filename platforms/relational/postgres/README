
modeling :
- creating all tables with the same structure for simplicity.
- author data must be ordered, so creating all tables with structure 'joinkey', 'sort order', 'data', 'pointer to evidence id'
- - if order is meaningless set value to 1
- each .ace Class maps to a 3-letter datatype prefix shortcut in postgres to associate related tables with this prefix
- if all objects don't have a required field, will probably need a table to keep track of objects that exist.
- data that maps directly to a .ace #Evidence maps to a table whose data is the name of the object (like ?Paper has Abstract that points at LongText)
- only creating an evidence entry if there is some evidence, might be faster to always create use the next sequence value and set it in the row, then in the future the evidence can be altered without the row needing an evidence ID added to it.


scripts :

populate_yaceA.pl
- create 1609170 rows, update 247743 sequence (evidence)
- 15 minutes to process data without touching postgres
- 4 hours 16 min 40 sec to run with perl DBI INSERT commands (15:09:51 to 19:26:31)
- 15 minutes 51 sec to write and copy (21:16:22 to 21:33:13)
- 66 seconds to copy data to tables with psql from command line
- 66Mb (68267574) size postgres dump
- parser is stripping all backslashes, should find out which characters are escaped, and only remove backslashes from those.

concise updates :
script update_yaceA_concise.pl
updating 10000 times took 89.4767119884491 seconds
updating 10000 times took 86.3572800159454 seconds
updating 10000 times took 88.3166408538818 seconds
process :
- get all genes with concise description
- 10000 times choose one randomly and perl DBI update table gin_concise_description changing data column by joinkey of WBGeneID

gene updates :
script update_yaceA_geneRnaiPhenotype.pl
creating 10000 updates with 60000 table changes took 589.331768035889 seconds
creating 10000 updates with 60000 table changes took 562.089204072952 seconds
creating 10000 updates with 60000 table changes took 589.936491966248 seconds
- each annotation has 6 table row entries
- - forward and backward phenotype-rnai
- - forward and backward gene-rnai, each with separate evidence
process :
- get all genes with public_name
- get all phenotype with primary_name
- get highest existing WBRNAi ID.
- 10000 times 
- - generate a new WBRNAi ID
- - randomly choose a WBGene and WBPhenotype
- - assign phenotype-rnai mappings to tables  'phe_rnai'  and  'rna_phenotype'
- - assign gene-rnai mappings to tables  'gin_rnai'  and  'rna_gene'  
- - - get the next evidence id from evi_sequence for gene to rnai mapping
- - - assign inferred automatically always to be 'RNAi_primary' to table  'evi_inferred_automatically' to evidence id
- - - assign 'gin_rnai' mapping to gene and rnai with evidence 
- - - get the next evidence id from evi_sequence for reverse (rnai to gene mapping)
- - - assign inferred automatically always to be 'RNAi_primary' to table  'evi_inferred_automatically' to evidence id
- - - assign 'rna_gene' mapping to rnai and gene with evidence 


to install :
install postgresql (came by default on ubuntu)
install libdbd-pg (I used synaptic)
$ cpan install Tie::IxHash
$ createdb yaceadb
put Kevin's dump*.ace into ace_source/ directory
$ ./create_yace_tables.pl
$ ./populate_yaceA.pl > populate_yaceA.out



files : 
  not all files are in github, don't see point of uploading large source files here, when they're also somewhere else ;  likewise files generated by these scripts.
create_yace_tables.pl
  wipe and recreate yace[a-c]db creating the tables and sequence
parsed_data	
  the data from dump*.ace files, parsed for structure
populate_yaceA.pl	
  1 - parse dump*.ace or test*.ace files 
  2 - write parsed_data or not
  3a - use perl DBI to insert to postgres directly line by line
  3b - write to flatfiles in postgres dump format, and copy data to postgres tables
populate_yaceA.out
  output of perl script postgres population (parsed_data + sql commands)
README
  this file
repopulate_yaceA
  commands to drop and copy tables, and reset sequence
  to repopulate postgres, do 
    psql -e yaceadb < repopulate_yaceA
schema.yaceadb
  schema dump of yacedb
table_dumps/
  directory where postgres table dumps are written to
update_yaceA_concise.pl*
  test time to 10000 times update concise description of random genes
update_yaceA_geneRnaiPhenotype.pl*
  test time to 10000 times generate a new RNAi objects and attach to random gene + phenotype
yaceadb.pg
  full dump of yaceC postgres database yaceadb
ace_source/
  directory for files : dump*.ace, test*.ace, models.wrm 
ace_source/dump*.ace
  .ace files from Kevin Howe's smallace database
ace_source/test.ace
  sample .ace file for testing
postgresql_autodoc/
   directory for files generated by postgresql_autodoc to see database schema
junk/
  directory for temporary files, no longer needed
